{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kgvBJM2VnwTx"
      },
      "outputs": [],
      "source": [
        "!pip3 install datasets transformers -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iYxZUdjVnlpj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from sklearn import metrics\n",
        "from datasets import load_dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from dataloaders import GoEmotionsSoft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "27769d45306a4c158bd2c1e1253b7315",
            "23deb95e10424cab91d43bcc2b2ec9d2",
            "38ca74a00a164f309e1e8404ab2f7e71",
            "fe2ddbae9c7749379e59c607720a23e2",
            "dbeb3f416c634ddeb8f22ab992b9de7f",
            "4d8596c8cbc246b1a9cdf522b10a35f0",
            "e436458514834371b5000967f690793d",
            "4b551ecf07ed4e9d9fd53d2b5789f302",
            "adbff1df856c482f901fb36d8bb38f61",
            "aa858db7930d4b0e92593b273c884a75",
            "3798c67b8dd34ff4a3549826a72b4655"
          ]
        },
        "id": "MaCI-VjH1-Sc",
        "outputId": "c8ce2738-0280-4825-9c77-f1351607b9d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No config specified, defaulting to: go_emotions/simplified\n",
            "Found cached dataset go_emotions (/Users/robertthomas/.cache/huggingface/datasets/go_emotions/simplified/0.0.0/2637cfdd4e64d30249c3ed2150fa2b9d279766bfcd6a809b9f085c61a90d776d)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3df07688c90f4cb2b5f266c90f6b138f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "go_emotions = load_dataset(\"go_emotions\")\n",
        "data = go_emotions.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rbsLOva32EmI"
      },
      "outputs": [],
      "source": [
        "train, valid, test = data[\"train\"].to_pandas(), data[\"validation\"].to_pandas(), data[\"test\"].to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FItxGCsL-bZF"
      },
      "outputs": [],
      "source": [
        "train_text = train[\"text\"].tolist()\n",
        "train_labels = train[\"labels\"].tolist()\n",
        "valid_text = valid[\"text\"].tolist()\n",
        "valid_labels = valid[\"labels\"].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "w8Dj5wvy_bfk"
      },
      "outputs": [],
      "source": [
        "text = train_text+valid_text\n",
        "labels = train_labels+valid_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VlK8tloW-nmL"
      },
      "outputs": [],
      "source": [
        "text = pd.DataFrame(text)\n",
        "text.rename({0: 'text'}, axis=1, inplace=True)\n",
        "labels= pd.DataFrame(labels)\n",
        "labels.rename({0: 'emotions'}, axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "n6Amw18A_Qv2",
        "outputId": "ee558917-d681-4229-86ec-7fd3596a52b0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My favourite food is anything I didn't have to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Now if he does off himself, everyone will thin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>To make her feel threatened</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dirty Southern Wankers</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  My favourite food is anything I didn't have to...\n",
              "1  Now if he does off himself, everyone will thin...\n",
              "2                     WHY THE FUCK IS BAYLESS ISOING\n",
              "3                        To make her feel threatened\n",
              "4                             Dirty Southern Wankers"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "H9bNaA8y_SBk",
        "outputId": "8edb0c8c-01d8-4e63-ffca-25d910f952b3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotions</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   emotions   1   2   3   4\n",
              "0        27 NaN NaN NaN NaN\n",
              "1        27 NaN NaN NaN NaN\n",
              "2         2 NaN NaN NaN NaN\n",
              "3        14 NaN NaN NaN NaN\n",
              "4         3 NaN NaN NaN NaN"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rqtIO6l3_oG0"
      },
      "outputs": [],
      "source": [
        "labels = labels.drop([1,2,3,4], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wTl2nEXS6Eas"
      },
      "outputs": [],
      "source": [
        "data = pd.concat([text, labels], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZxjA7vHz7sWk",
        "outputId": "a8a1220c-0f6b-4782-aa6e-d511674fbadf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My favourite food is anything I didn't have to...</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Now if he does off himself, everyone will thin...</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>To make her feel threatened</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dirty Southern Wankers</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  emotions\n",
              "0  My favourite food is anything I didn't have to...        27\n",
              "1  Now if he does off himself, everyone will thin...        27\n",
              "2                     WHY THE FUCK IS BAYLESS ISOING         2\n",
              "3                        To make her feel threatened        14\n",
              "4                             Dirty Southern Wankers         3"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nWYhNTPi2OSU"
      },
      "outputs": [],
      "source": [
        "mapping = {\n",
        "    0:\"admiration\",\n",
        "    1:\"amusement\",\n",
        "    2:\"anger\",\n",
        "    3:\"annoyance\",\n",
        "    4:\"approval\",\n",
        "    5:\"caring\",\n",
        "    6:\"confusion\",\n",
        "    7:\"curiosity\",\n",
        "    8:\"desire\",\n",
        "    9:\"disappointment\",\n",
        "    10:\"disapproval\",\n",
        "    11:\"disgust\",\n",
        "    12:\"embarrassment\",\n",
        "    13:\"excitement\",\n",
        "    14:\"fear\",\n",
        "    15:\"gratitude\",\n",
        "    16:\"grief\",\n",
        "    17:\"joy\",\n",
        "    18:\"love\",\n",
        "    19:\"nervousness\",\n",
        "    20:\"optimism\",\n",
        "    21:\"pride\",\n",
        "    22:\"realization\",\n",
        "    23:\"relief\",\n",
        "    24:\"remorse\",\n",
        "    25:\"sadness\",\n",
        "    26:\"surprise\",\n",
        "    27:\"neutral\",\n",
        "}\n",
        "\n",
        "n_labels = len(mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7hkw6s2b7_6D",
        "outputId": "31bd836f-6fee-4ccb-e6ff-6cadeccfcc8b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My favourite food is anything I didn't have to...</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Now if he does off himself, everyone will thin...</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>To make her feel threatened</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dirty Southern Wankers</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  emotions\n",
              "0  My favourite food is anything I didn't have to...        27\n",
              "1  Now if he does off himself, everyone will thin...        27\n",
              "2                     WHY THE FUCK IS BAYLESS ISOING         2\n",
              "3                        To make her feel threatened        14\n",
              "4                             Dirty Southern Wankers         3"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "pAuo0-NT8DyL"
      },
      "outputs": [],
      "source": [
        "emotions=[]\n",
        "for i in data.emotions:\n",
        "    emotions.append(mapping[i])\n",
        "  \n",
        "data['emotions']=emotions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "N3ujnsDC8_Sz",
        "outputId": "ad3731f6-ceef-4221-b63c-5268c2e17888"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My favourite food is anything I didn't have to...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Now if he does off himself, everyone will thin...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>To make her feel threatened</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dirty Southern Wankers</td>\n",
              "      <td>annoyance</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text   emotions\n",
              "0  My favourite food is anything I didn't have to...    neutral\n",
              "1  Now if he does off himself, everyone will thin...    neutral\n",
              "2                     WHY THE FUCK IS BAYLESS ISOING      anger\n",
              "3                        To make her feel threatened       fear\n",
              "4                             Dirty Southern Wankers  annoyance"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8n7hjzBJ3Ili",
        "outputId": "419cdfd5-52a7-4f9a-eff8-6c04a0325dec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "703\n"
          ]
        }
      ],
      "source": [
        "max_len = 0\n",
        "all_len=[]\n",
        "for i in data.text:\n",
        "    all_len.append(len(i))\n",
        "    max_len=max(max_len,len(i))\n",
        "print(max_len)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "PVqVJLxr35ur",
        "outputId": "2b0b50f1-fa03-4287-c804-47998198fbdf"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.hist(all_len)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "0I_EBLdI5a_E"
      },
      "outputs": [],
      "source": [
        "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
        "# (e.g., 5 -> \"dad\") for the dataset\n",
        "class ConstructVocab():\n",
        "    def __init__(self, sentences):\n",
        "        self.sentences = sentences\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "        \n",
        "    def create_index(self):\n",
        "        for s in self.sentences:\n",
        "            # update with individual tokens\n",
        "            self.vocab.update(s.split(' '))\n",
        "            \n",
        "        # sort the vocab\n",
        "        self.vocab = sorted(self.vocab)\n",
        "\n",
        "        # add a padding token with index 0\n",
        "        self.word2idx['<pad>'] = 0\n",
        "        \n",
        "        # word to index mapping\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1 # +1 because of pad token\n",
        "        \n",
        "        # index to word mapping\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cu5Ea2H9yAj",
        "outputId": "4ba78b23-e60d-4748-9b5b-5b70824ad91f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data.loc[0].text.split(' '))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5r65tGRqHexE",
        "outputId": "b3d49ba5-76e8-4c42-ce91-7360bfea4abe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "48836"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "F98IXhHr44Xq"
      },
      "outputs": [],
      "source": [
        "data[\"token_size\"] = data[\"text\"].apply(lambda x: len(x.split(' ')))\n",
        "data = data.loc[data['token_size'] < 200].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kECB6sQpA_Mz",
        "outputId": "a0c1840f-95d7-4821-91b1-41f5ee3b080a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "      <th>token_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My favourite food is anything I didn't have to...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Now if he does off himself, everyone will thin...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
              "      <td>anger</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>To make her feel threatened</td>\n",
              "      <td>fear</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dirty Southern Wankers</td>\n",
              "      <td>annoyance</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text   emotions  token_size\n",
              "0  My favourite food is anything I didn't have to...    neutral          11\n",
              "1  Now if he does off himself, everyone will thin...    neutral          20\n",
              "2                     WHY THE FUCK IS BAYLESS ISOING      anger           6\n",
              "3                        To make her feel threatened       fear           5\n",
              "4                             Dirty Southern Wankers  annoyance           3"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AteYYlCE9cqk",
        "outputId": "34cefc4f-4773-4b86-dddd-c1c4f6636750"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    48836.000000\n",
              "mean        12.897453\n",
              "std          6.738225\n",
              "min          1.000000\n",
              "25%          7.000000\n",
              "50%         12.000000\n",
              "75%         18.000000\n",
              "max         33.000000\n",
              "Name: token_size, dtype: float64"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['token_size'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wKsB1glf5BSV"
      },
      "outputs": [],
      "source": [
        "inputs = ConstructVocab(data[\"text\"].values.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "M-QySAfg7KYx"
      },
      "outputs": [],
      "source": [
        "# vectorize to tensor\n",
        "input_tensor = [[inputs.word2idx[s] for s in es.split(' ')]  for es in data[\"text\"].values.tolist()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "JCEzjuDr7T-0"
      },
      "outputs": [],
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfYge-H47Wsj",
        "outputId": "444cd974-30f5-4ec9-d14c-58a9859fbaf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "33\n"
          ]
        }
      ],
      "source": [
        "# calculate the max_length of input tensor\n",
        "max_length_inp = max_length(input_tensor)\n",
        "print(max_length_inp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "RFbJvehZ7X4J"
      },
      "outputs": [],
      "source": [
        "def pad_sequences(x, max_len):\n",
        "    padded = np.zeros((max_len), dtype=np.int64)\n",
        "    if len(x) > max_len: padded[:] = x[:max_len]\n",
        "    else: padded[:len(x)] = x\n",
        "    return padded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ioRUfHmm7aIG"
      },
      "outputs": [],
      "source": [
        "# inplace padding\n",
        "input_tensor = [pad_sequences(x, max_length_inp) for x in input_tensor]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ij4cCs0L7bo-",
        "outputId": "bf174daf-a28a-4891-8d5b-6e0e0517fefe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([12922, 32633, 33405, 38438, 21180, 10602, 29323, 35848, 56020,\n",
              "        27258, 42732,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0]),\n",
              " array([13396, 37260, 35892, 29964, 43860, 36389, 31702, 59248, 55556,\n",
              "        36259, 35867, 19663, 39519, 50661, 59396, 45403, 38058, 43847,\n",
              "        20033, 28465,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0])]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_tensor[0:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "aVuBlsE47c3r"
      },
      "outputs": [],
      "source": [
        "### convert targets to one-hot encoding vectors\n",
        "emotions = list(set(data.emotions.unique()))\n",
        "num_emotions = len(emotions)\n",
        "# binarizer\n",
        "mlb = preprocessing.MultiLabelBinarizer()\n",
        "data_labels =  [set(emos) & set(emotions) for emos in data[['emotions']].values]\n",
        "bin_emotions = mlb.fit_transform(data_labels)\n",
        "target_tensor = np.array(bin_emotions.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si_CoU6y70ds",
        "outputId": "725bd1db-d4f7-43c3-f496-40802de77010"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "        0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "        0, 0, 0, 0, 0, 0]])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_tensor[0:2] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "3DygtOH2Huhj",
        "outputId": "f5fb3ca0-71f6-47bc-bc7c-fe8735a667f2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "      <th>token_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My favourite food is anything I didn't have to...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Now if he does off himself, everyone will thin...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text emotions  token_size\n",
              "0  My favourite food is anything I didn't have to...  neutral          11\n",
              "1  Now if he does off himself, everyone will thin...  neutral          20"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[0:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "QY3QtMXPHwLL"
      },
      "outputs": [],
      "source": [
        "get_emotion = lambda t: np.argmax(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtLvKtPnHxmO",
        "outputId": "558b0482-9f37-4f7b-ccd3-e3ef71ca1fe7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_emotion(target_tensor[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pzUK_DGkHyby",
        "outputId": "3c3bdbae-019f-4f6b-b0bd-abc570d1579d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'optimism'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emotion_dict=mapping\n",
        "emotion_dict[get_emotion(target_tensor[0])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT1E4kuDH6TX",
        "outputId": "fbed374f-643c-47fa-b3b0-defaa4326b37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "int64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(39068, 39068, 4884, 4884, 4884, 4884)"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "print(input_tensor_train[0].dtype)\n",
        "\n",
        "# Split the validataion further to obtain a holdout dataset (for testing) -- split 50:50\n",
        "input_tensor_val, input_tensor_test, target_tensor_val, target_tensor_test = train_test_split(input_tensor_val, target_tensor_val, test_size=0.5)\n",
        "\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val), len(input_tensor_test), len(target_tensor_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "AGsuliHLH74z"
      },
      "outputs": [],
      "source": [
        "TRAIN_BUFFER_SIZE = len(input_tensor_train)\n",
        "VAL_BUFFER_SIZE = len(input_tensor_val)\n",
        "TEST_BUFFER_SIZE = len(input_tensor_test)\n",
        "BATCH_SIZE = 64\n",
        "TRAIN_N_BATCH = TRAIN_BUFFER_SIZE // BATCH_SIZE\n",
        "VAL_N_BATCH = VAL_BUFFER_SIZE // BATCH_SIZE\n",
        "TEST_N_BATCH = TEST_BUFFER_SIZE // BATCH_SIZE\n",
        "\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inputs.word2idx)\n",
        "target_size = num_emotions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "98nzRBdtH-lS"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "OOqDvAeBH_g_"
      },
      "outputs": [],
      "source": [
        "# convert the data to tensors and pass to the Dataloader \n",
        "# to create an batch iterator\n",
        "\n",
        "class MyData(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.data = X\n",
        "        self.target = y\n",
        "        self.length = [ np.sum(1 - np.equal(x, 0)) for x in X]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        x_len = self.length[index]\n",
        "        return x, y, x_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "ose0QwduIATZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<dataloaders.GoEmotionsSoft object at 0x7fa0ec4b8250>\n"
          ]
        }
      ],
      "source": [
        "train_logits = torch.zeros((50000, n_labels))\n",
        "\n",
        "train_dataset = GoEmotionsSoft(input_tensor_train, target_tensor_train, train_logits)\n",
        "val_dataset = MyData(input_tensor_val, target_tensor_val)\n",
        "test_dataset = MyData(input_tensor_test, target_tensor_test)\n",
        "\n",
        "print(train_dataset)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE, \n",
        "                     drop_last=True,\n",
        "                     shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbpHstQSIBM6",
        "outputId": "9b715327-f6f2-462f-c03d-e7c2b19b7749"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_loader.batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "7tLtVjOKIB7x"
      },
      "outputs": [],
      "source": [
        "class EmoGRU(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_units, batch_sz, output_size):\n",
        "        super(EmoGRU, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.hidden_units = hidden_units\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        # layers\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.gru = nn.GRU(self.embedding_dim, self.hidden_units)\n",
        "        self.fc = nn.Linear(self.hidden_units, self.output_size)\n",
        "    \n",
        "    def initialize_hidden_state(self, device):\n",
        "        return torch.zeros((1, self.batch_sz, self.hidden_units)).to(device)\n",
        "    \n",
        "    def forward(self, x, lens, device):\n",
        "        x = self.embedding(x)\n",
        "        self.hidden = self.initialize_hidden_state(device)\n",
        "        output, self.hidden = self.gru(x, self.hidden) # max_len X batch_size X hidden_units\n",
        "        out = output[-1, :, :] \n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        return out, self.hidden  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "cPy-EB9mIDDH"
      },
      "outputs": [],
      "source": [
        "### sort batch function to be able to use with pad_packed_sequence\n",
        "def sort_batch(X, y, lengths, logits):\n",
        "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
        "    X = X[indx]\n",
        "    y = y[indx]\n",
        "    logits = logits[indx]\n",
        "    return X.transpose(0,1), y, lengths, logits # transpose (batch x seq) to (seq x batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txnH6QmmIEgE",
        "outputId": "eecb521a-366b-4355-bee5-f63dfb0e43ce"
      },
      "outputs": [],
      "source": [
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "# model.to(device)\n",
        "\n",
        "# # obtain one sample from the data iterator\n",
        "# it = iter(train_dataset)\n",
        "# x, y, x_len, logits = next(it)\n",
        "\n",
        "# # sort the batch first to be able to use with pac_pack sequence\n",
        "# xs, ys, lens, logits = sort_batch(x, y, x_len, logits)\n",
        "\n",
        "# print(\"Input size: \", xs.size())\n",
        "\n",
        "# output, _ = model(xs.to(device), lens, device)\n",
        "# print(output.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "Cge8ckJjIGD-"
      },
      "outputs": [],
      "source": [
        "### Enabling cuda\n",
        "use_cuda = True if torch.cuda.is_available() else False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = EmoGRU(vocab_inp_size, embedding_dim, units, BATCH_SIZE, target_size)\n",
        "model.to(device)\n",
        "\n",
        "### loss criterion and optimizer for training\n",
        "criterion = nn.CrossEntropyLoss() # the same as log_softmax + NLLLoss\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "def loss_function(y, prediction):\n",
        "    \"\"\" CrossEntropyLoss expects outputs and class indices as target \"\"\"\n",
        "    # convert from one-hot encoding to class indices\n",
        "    target = torch.max(y, 1)[1]\n",
        "    loss = criterion(prediction, target) \n",
        "    return loss   #TODO: refer the parameter of these functions as the same\n",
        "    \n",
        "def accuracy(target, logit):\n",
        "    ''' Obtain accuracy for training round '''\n",
        "    target = torch.max(target, 1)[1] # convert from one-hot encoding to class indices\n",
        "    corrects = (torch.max(logit, 1)[1].data == target).sum()\n",
        "    accuracy = 100.0 * corrects / len(logit)\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_normal(epoch, train_loader, model, criterion, optimizer, options, train_logits):\n",
        "    model.train()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        train_logits=train_logits.cuda()\n",
        "    \n",
        "    for idx, (image, labels, lens, softlabel, index) in enumerate(train_loader):\n",
        "        image = image.float()\n",
        "        if torch.cuda.is_available():\n",
        "            image = image.cuda()\n",
        "            labels = labels.cuda()\n",
        "        image = image.int()\n",
        "        output, _ = model(image.permute(1 ,0).to(device), lens, device)\n",
        "        train_logits[index] = output\n",
        "        loss = criterion(output, labels.argmax(dim=1))\n",
        "        acc1 = accuracy(output, labels)\n",
        "        losses.update(loss.item(), image.size(0))\n",
        "        top1.update(acc1.item(), image.size(0))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    return top1.avg, losses.avg, train_logits\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_lwr(epoch, train_loader, model, criterion_list, optimizer, options, train_logits):\n",
        "    model.train()\n",
        "    if torch.cuda.is_available():\n",
        "        train_logits=train_logits.cuda()\n",
        "\n",
        "    criterion_cls = criterion_list[0]\n",
        "    critetion_soft = criterion_list[1]\n",
        "    criterion_kl = criterion_list[2]\n",
        "\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "\n",
        "    \n",
        "    for idx, data in enumerate(train_loader):\n",
        "        image, labels, lens, logits, index = data\n",
        "        image = image.float()\n",
        "        if torch.cuda.is_available():\n",
        "            image = image.cuda().int()\n",
        "            labels = labels.cuda()\n",
        "            logits = logits.cuda()\n",
        "        \n",
        "        soft_label = critetion_soft(logits)        \n",
        "        preact = False\n",
        "        logit_s, _ = model(image.permute(1 ,0).to(device), lens, device)\n",
        "        train_logits[index] = logit_s\n",
        "        loss_cls = criterion_cls(logit_s, labels.argmax(dim=1))        \n",
        "        loss_kl = criterion_kl(logit_s, soft_label)\n",
        "\n",
        "        if epoch<=options[\"k\"]:\n",
        "            loss = loss_cls \n",
        "        else:\n",
        "            num_5 = int(epoch/options[\"k\"])\n",
        "            cure = num_5*options[\"k\"]\n",
        "            \n",
        "            loss = (options[\"gamma\"]+(1-cure/240)*(1-options[\"gamma\"])) * loss_cls + cure/240*(1-options[\"gamma\"])* loss_kl\n",
        "\n",
        "        acc1 = accuracy(logit_s, labels)\n",
        "        losses.update(loss.item(), image.size(0))\n",
        "        top1.update(acc1[0], image.size(0))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return top1.avg, losses.avg, train_logits\n",
        "\n",
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def validate(val_loader, model, criterion, options):\n",
        "    \n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for idx, (image, label, lens) in enumerate(val_loader):\n",
        "\n",
        "            image = image.float()\n",
        "            if torch.cuda.is_available():\n",
        "                image = image.cuda()\n",
        "                label = label.cuda()\n",
        "\n",
        "            output, _ = model(image.permute(1 ,0).to(device), lens, device)\n",
        "            loss = criterion(output, label)\n",
        "            acc1 = accuracy(output, label)\n",
        "            losses.update(loss.item(), image.size(0))\n",
        "            top1.update(acc1[0], image.size(0))\n",
        "            \n",
        "    return top1.avg,losses.avg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dulhJwAWIIcN",
        "outputId": "aa7ebd6b-dcbe-4a85-aa05-b7b269502639"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-3dbe4c0703fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"k\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_logits\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_logits\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_lwr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-105-d15fe0cab152>\u001b[0m in \u001b[0;36mtrain_normal\u001b[0;34m(epoch, train_loader, model, criterion, optimizer, options, train_logits)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtop1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/lasaft/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/lasaft/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "options = {\n",
        "    \"epochs\": 20,\n",
        "    \"arch\": \"EmoGRU\",\n",
        "    \"k\": 5,\n",
        "    \"gamma\": 0.9\n",
        "}\n",
        "\n",
        "best_acc = 0\n",
        "for epoch in range(1, int(options[\"epochs\"])+ 1):\n",
        "\n",
        "        if epoch<=options[\"k\"]:\n",
        "            train_acc, train_loss, train_logits= train_normal(epoch, train_loader, model, criterion, optimizer, options, train_logits)\n",
        "        else:\n",
        "            train_acc, train_loss, train_logits= train_lwr(epoch, train_loader, model, criterion, optimizer, options, train_logits)\n",
        "         \n",
        "        \n",
        "        train_logits = train_logits.detach().cpu()\n",
        "            \n",
        "        if epoch>=options[\"k\"] and epoch%options[\"k\"]==0:\n",
        "            print('label update')\n",
        "            train_dataset = GoEmotionsSoft(input_tensor_train, target_tensor_train, train_logits)\n",
        "            train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, \n",
        "                                drop_last=True,\n",
        "                                shuffle=True)\n",
        "        \n",
        "        print('epoch {}'.format(epoch))\n",
        "\n",
        "\n",
        "        test_acc, test_loss = validate(val_loader, model, criterion, options)\n",
        "\n",
        "        print(\"Current Test Accuracy:\",test_acc)\n",
        "        # calculate best accuracy.\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "        \n",
        "        print('best accuracy:', best_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpYWM5M1IKYk",
        "outputId": "ab777f26-781a-40a7-88a6-f862e3030f82"
      },
      "outputs": [],
      "source": [
        "model.parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-txJgHzHh1L"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unJHGI93HimL",
        "outputId": "3e8df577-4478-411c-f0a3-454d735368c5"
      },
      "outputs": [],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTqFjYNCJgHa",
        "outputId": "965a5f7d-d3f6-4212-fbd0-3f08b0288253"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(\"/content/model.pth\"))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mcGYSoNIL7x",
        "outputId": "16e766c8-f521-4225-e932-607fbaa5b959"
      },
      "outputs": [],
      "source": [
        "test_accuracy = 0\n",
        "all_predictions = []\n",
        "x_raw = []\n",
        "y_raw = []\n",
        "\n",
        "#device = \"cuda\" # we don't need GPU to do testing\n",
        "model.to(\"cpu\")\n",
        "\n",
        "for (batch, (inp, targ, lens)) in enumerate(test_dataset):          \n",
        "    predictions,_ = model(inp.permute(1, 0).to(device), lens, device)        \n",
        "    batch_accuracy = accuracy(targ.to(device), predictions)\n",
        "    test_accuracy += batch_accuracy\n",
        "    \n",
        "    x_raw = x_raw + [x for x in inp]\n",
        "    y_raw = y_raw + [y for y in targ]\n",
        "    \n",
        "    all_predictions.append(predictions)\n",
        "    \n",
        "print(\"Test Accuracy: \", test_accuracy.cpu().detach().numpy() / TEST_N_BATCH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFMaLNCWTwiL"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"/content/model.pth\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('lasaft')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "ea2d8fc23e5e8cb0e61c2f5d4fa8cd99ee86b406970893140fc11ca02cafb4ee"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "23deb95e10424cab91d43bcc2b2ec9d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d8596c8cbc246b1a9cdf522b10a35f0",
            "placeholder": "​",
            "style": "IPY_MODEL_e436458514834371b5000967f690793d",
            "value": "100%"
          }
        },
        "27769d45306a4c158bd2c1e1253b7315": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23deb95e10424cab91d43bcc2b2ec9d2",
              "IPY_MODEL_38ca74a00a164f309e1e8404ab2f7e71",
              "IPY_MODEL_fe2ddbae9c7749379e59c607720a23e2"
            ],
            "layout": "IPY_MODEL_dbeb3f416c634ddeb8f22ab992b9de7f"
          }
        },
        "3798c67b8dd34ff4a3549826a72b4655": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38ca74a00a164f309e1e8404ab2f7e71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b551ecf07ed4e9d9fd53d2b5789f302",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_adbff1df856c482f901fb36d8bb38f61",
            "value": 3
          }
        },
        "4b551ecf07ed4e9d9fd53d2b5789f302": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d8596c8cbc246b1a9cdf522b10a35f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa858db7930d4b0e92593b273c884a75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adbff1df856c482f901fb36d8bb38f61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbeb3f416c634ddeb8f22ab992b9de7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e436458514834371b5000967f690793d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe2ddbae9c7749379e59c607720a23e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa858db7930d4b0e92593b273c884a75",
            "placeholder": "​",
            "style": "IPY_MODEL_3798c67b8dd34ff4a3549826a72b4655",
            "value": " 3/3 [00:00&lt;00:00, 56.43it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
